<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GCN</title>
      <link href="/2023/03/25/GCN/"/>
      <url>/2023/03/25/GCN/</url>
      
        <content type="html"><![CDATA[<h1 id="GCN-图卷积神经网络"><a href="#GCN-图卷积神经网络" class="headerlink" title="GCN 图卷积神经网络"></a>GCN 图卷积神经网络</h1><p><em>无穷的远方，无数的人们，都和我有关。——鲁迅《且介亭杂文末集·这也是生活》</em></p><h2 id="1-将节点映射为d维向量"><a href="#1-将节点映射为d维向量" class="headerlink" title="1. 将节点映射为d维向量"></a>1. 将节点映射为d维向量</h2><p>图神经网络的基本原理是：</p><p><strong>将图中节点编码映射成一个低维连续稠密的d维向量</strong></p><p>d可以为128、256…</p><p>这个向量可以反映在原图的属性关系</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325195204078.png" alt="图1.1 节点映射为d维向量" style="zoom:80%;" /></p><h2 id="2-计算图"><a href="#2-计算图" class="headerlink" title="2. 计算图"></a>2. 计算图</h2><h3 id="2-1-通过局部邻域构建计算图"><a href="#2-1-通过局部邻域构建计算图" class="headerlink" title="2.1 通过局部邻域构建计算图"></a>2.1 通过局部邻域构建计算图</h3><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325152228320.png" alt="图2.1.1 计算图" style="zoom:80%;" /></p><p>每个节点可以分别构建自己的计算图</p><p>例如图2.1中的图，每个节点对应的计算图如下所示</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325152531870.png" alt="图2.1.2 每个节点对应的计算图" style="zoom:67%;" /></p><p>在计算图中，所有的黑色神经网络共享一套参数，所有的白色神经网络共享一套参数。</p><h3 id="2-2-图神经网络层数"><a href="#2-2-图神经网络层数" class="headerlink" title="2.2 图神经网络层数"></a>2.2 图神经网络层数</h3><p><strong>图神经网络的层数，是计算图的层数，而不是神经网络的层数。</strong></p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325152854348.png" alt="图2.2.1 图神经网络的层数" style="zoom:67%;" /></p><p>上图的图神经网络层数为2，因为计算图为2层。Layer-1、Layer-2中的神经网络层数可以为任意大小。Layer-0为节点的属性特征，是自带的，无须学习。 </p><p>图神经网络（计算图）可以任意深，但是根据“六度空间”理论，理论上已经可以得到所有信息。</p><p>图神经网络不能无限深，因为会导致所有计算图的节点都很类似，会产生过平滑（over smoothing）问题。所有节点的嵌入都会收敛到同一个值，即所有节点的embedding都相同。因此图神经网络一般两三层就足够了。</p><p>计算图的原理：</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325154822470.png" alt="图2.2.2 两层计算图原理" style="zoom:67%;" /></p><p>左图是过程，右图目标节点是最终得到的计算图</p><h3 id="2-3-K层GCC的感受野"><a href="#2-3-K层GCC的感受野" class="headerlink" title="2.3 K层GCC的感受野"></a>2.3 K层GCC的感受野</h3><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325153428719.png" alt="图2.3.1 K层GCC的感受野" style="zoom:67%;" /></p><p>1-layer就是目标节点的邻居</p><p>2-layer就是目标节点邻居的邻居</p><p>3-layer就是目标节点邻居的邻居的邻居</p><p><em>层数越多，感受野越大。感受野这个词还是挺形象的</em></p><h3 id="2-4-举个例子"><a href="#2-4-举个例子" class="headerlink" title="2.4 举个例子"></a>2.4 举个例子</h3><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325155341547.png" alt="图2.4.1 无自身信息的图卷积神经网络" style="zoom:80%;" /></p><p>每个节点都是128*1的向量</p><p>图卷积神经网络第一层：</p><ul><li>计算B的embedding时，A和C逐元素求平均，得到一个新的128*1维的向量。输入到黑色卷积神经网络中， 输出为512*1维度的向量。</li><li>计算C的embedding，就是计算ABEF的平均，得到128维向量，卷积后输出512维向量。</li><li>D同理。 </li></ul><p>第二层：</p><ul><li>BCD逐元素求平均，得到新的512维的向量，输入到白色卷积神经网络中，最终得到256维A的embedding，作为A节点的输出。</li></ul><h2 id="3-数学形式"><a href="#3-数学形式" class="headerlink" title="3. 数学形式"></a>3. 数学形式</h2><h3 id="3-1-数学公式表示"><a href="#3-1-数学公式表示" class="headerlink" title="3.1 数学公式表示"></a>3.1 数学公式表示</h3><script type="math/tex; mode=display">h_v^{(0)}=x_v \\h_v^{(k+1)}=\alpha(W_k\sum_{u \in N(v)}\frac{h_u^k}{|N(v)|})\\z_v=h_v^K\\</script><ul><li>第0层的属性嵌入就是每个节点的属性特征。</li><li>k+1层v节点的嵌入是由第k层邻域节点u算出来的。其实就是对k层节点求平均后输入到卷积神经网络，经过非线性激活，得到k+1层嵌入。这是一个递归的过程。</li><li>假设这个卷积神经网络只有两层，K=2，就以第二层v节点的z作为最后的输出的embedding。</li></ul><h3 id="3-2-矩阵表示"><a href="#3-2-矩阵表示" class="headerlink" title="3.2 矩阵表示"></a>3.2 矩阵表示</h3><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325164450391.png" alt="图3.2.1 矩阵表示的每一步解释" style="zoom:70%;" /></p><ul><li><p>第k层所有的嵌入为$H^{(k)}=[h_1^{(k)}…h_{|V|}^{(k)}]^T$，在这个大矩阵中，每个节点的嵌入就是其中一行。</p></li><li><p>对$H$矩阵左乘一个邻接矩阵A的第v行，也就是$A_vH^{(k)}$，就可以把$v$节点的邻域节点挑出来，得到v节点的embedding。其实也就是求和的过程。</p></li><li><p>求平均的过程：找出一个$D$矩阵（一个对角矩阵）， 每个元素是对应节点的连接数。$D^{-1}AH^{(k)}$中的$D^{-1}$就是求平均的过程。</p></li><li><p>$D^{-1}A$是Row Normalized Matrix，<strong>最大特征值为1</strong>。</p></li></ul><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325170802811.png" alt="图3.2.2 计算$A_{row}$的一个例子" style="zoom:80%;" /></p><p>$A_{row}=D^{-1}A$的特点：</p><ul><li>$A_{row}$是一个非对称矩阵</li><li>$A_{col}$和$A_{row}$互为转置</li><li>最大特征值为1</li><li>只按照自己的度，对所有渠道来的信息强行求平均</li><li>没有考虑对方的连接数</li></ul><p><em>因此，使用$D^{-1}A$计算权重不太科学。</em></p><p><strong>最终，我们使用$A_{sym}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$</strong></p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325184824963.png" alt="图3.2.3 $D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$对应计算结果" style="zoom:80%;" /></p><p><strong>$A_{sym}=D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$的特点：</strong></p><ul><li><strong>$A_{sym}$是一个对称矩阵</strong></li><li><strong>最大特征值为1</strong></li></ul><h3 id="3-3-tilde-A-ij-含义"><a href="#3-3-tilde-A-ij-含义" class="headerlink" title="3.3 $\tilde{A_{ij}}$含义"></a>3.3 $\tilde{A_{ij}}$含义</h3><script type="math/tex; mode=display">\tilde{A_{ij}}=\frac{1}{\sqrt{d_i}\sqrt{d_j}}</script><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325190459336.png" alt="图3.3.1 $\tilde{A_{ij}}$的两种情况" style="zoom:80%;" /></p><ul><li>如果i和j直接相连，那么$\tilde{A_{ij}}$为1，此时关联程度较高</li><li>反之，关联程度较低，为$Small\tilde{A_{ij}}$</li></ul><p>$\tilde{A_{ij}}$被称为normalized diffusion matrix，有以下特征：</p><ul><li>在[-1,1]范围之间</li><li>最大值为1</li><li>$A_{sym}$其实就是$\tilde{A_{ij}}$</li><li>稀疏矩阵</li></ul><h3 id="3-4-最终版数学形式"><a href="#3-4-最终版数学形式" class="headerlink" title="3.4 最终版数学形式"></a>3.4 最终版数学形式</h3><script type="math/tex; mode=display">h_v^{(0)}=x_v \\h_v^{(k+1)}=\alpha(D^{-\frac{1}{2}}AD^{-\frac{1}{2}}H^{(k)}W^{(k)})\\z_v=h_v^K\\</script><p>$W^{(k)}$是可学习的参数矩阵</p><p>$D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$无需学习，图一旦确定，该矩阵就已经确定</p><h2 id="4-self-edge的GCN"><a href="#4-self-edge的GCN" class="headerlink" title="4. self edge的GCN"></a>4. self edge的GCN</h2><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325192732450.png" alt="图4.1 有self edge的GCN" style="zoom:80%;" /></p><p>添加了self embedding</p><h3 id="4-1-self-edge的数学形式"><a href="#4-1-self-edge的数学形式" class="headerlink" title="4.1 self edge的数学形式"></a>4.1 self edge的数学形式</h3><p>此时的数学形式为</p><script type="math/tex; mode=display">H_i^{(k)}=\alpha(\sum_{j \in \{N(i) \cup i\} }\frac{\tilde{A_{ij}}}{\sqrt{\tilde{D_{ij}}\tilde{D_{ij}}}}H_j^{(k-1)}W^{(k)})\\</script><p>或者可以写为</p><script type="math/tex; mode=display">H_i^{(k)}=\alpha(\sum_{j \in N(i)}\frac{\tilde{A_{ij}}}{\sqrt{\tilde{D_{ij}}\tilde{D_{ij}}}}H_j^{(k-1)}W^{(k)}+\frac{1}{\tilde{D_{ij}}}H_i^{(k-1)}W^{(k)})\\</script><h2 id="5-思考"><a href="#5-思考" class="headerlink" title="5. 思考"></a>5. 思考</h2><h3 id="5-1-半监督节点分类方法"><a href="#5-1-半监督节点分类方法" class="headerlink" title="5.1 半监督节点分类方法"></a>5.1 半监督节点分类方法</h3><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230325194130121.png" alt="图5.1.1 半监督节点分类方法对比" style="zoom:80%;" /></p><ol><li>人工特征工程：节点重要度、集群系数、Graphlet等。</li><li>基于随机游走的方法：构造自监督表示学习任务实现图嵌入。无法泛化到新节点。例如: DeepWalk、Node2Vec、LINE、SDNE等。</li><li>标签传播：假设“物以类聚，人以群分”，利用邻域节点类别猜测当前节点类别。无法泛化到新节点。例如: Label Propagation、Iterative Classification、Belief Propagation、Correct &amp; Smooth等。</li><li>图神经网络：利用深度学习和神经网络，构造邻域节点信息聚合计算图，实现节点嵌入和类别预测。可泛化到新节点。例如: GCN、GraphSAGE、GAT、GIN等.</li></ol><h3 id="5-2-图神经网络优点"><a href="#5-2-图神经网络优点" class="headerlink" title="5.2 图神经网络优点"></a>5.2 图神经网络优点</h3><ol><li><strong>深度学习拟合学习能力强</strong>，表示学习得到的嵌入向量质量高</li><li>站在深度学习巨人肩膀上</li><li><strong>归纳式</strong>学习能力Inductive Learning：泛化到新节点、新图</li><li><strong>参数量少</strong>、所有计算图<strong>共享</strong>神经网络</li><li>利用节点<strong>属性特征</strong></li><li>利用节点<strong>标注类别</strong></li><li>可以区分节点<strong>结构功能角色</strong> (桥接、中枢、外围边缘</li><li>只需寥寥几层，就可以让任意两个节点相互影响</li></ol><h3 id="5-3-GCN是直推的还是泛化的？"><a href="#5-3-GCN是直推的还是泛化的？" class="headerlink" title="5.3 GCN是直推的还是泛化的？"></a>5.3 GCN是直推的还是泛化的？</h3><ul><li>在直推的(transductive)的场景下，GCN 的目标是对于一个给定的图（即已经有标记的节点和边），对图中的每个节点进行分类、回归等任务。在这种情况下，GCN 能够从图中已有的标记信息中学习节点的特征，然后将这些特征用于任务中。</li><li>在泛化的(inductive)的场景下，GCN 的目标是从一个训练集中学习一个模型，并将该模型泛化到不同的图上。在这种情况下，GCN 通过从训练集中学习到的节点特征和图结构，生成一个通用的模型，然后将该模型用于新的图中。</li><li>在实践中，有些 GCN 方法只能用于 transductive 的场景，而有些 GCN 方法则能够处理 inductive 的场景。例如，原始的 GCN 模型只能处理 transductive 的场景，而后来的 GraphSAGE 模型则能够处理 inductive 的场景。通常情况下，inductive GCN 模型比 transductive GCN 模型更具有实用价值，因为它们能够泛化到新的、没有见过的图中。</li></ul><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a>6. 参考资料</h2><p><a href="https://www.bilibili.com/video/BV1Hs4y157Ls/?spm_id_from=333.788&amp;vd_source=5cf963abd0f635e31aa9385d489cf581">https://www.bilibili.com/video/BV1Hs4y157Ls/?spm_id_from=333.788&amp;vd_source=5cf963abd0f635e31aa9385d489cf581</a></p><p><a href="https://github.com/TommyZihao/zihao_course/blob/main/CS224W/6-3-GCN.md">https://github.com/TommyZihao/zihao_course/blob/main/CS224W/6-3-GCN.md</a></p>]]></content>
      
      
      <categories>
          
          <category> Graph Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GCN </tag>
            
            <tag> Graph Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GRU</title>
      <link href="/2023/03/23/GRU/"/>
      <url>/2023/03/23/GRU/</url>
      
        <content type="html"><![CDATA[<h1 id="GRU-门控循环单元"><a href="#GRU-门控循环单元" class="headerlink" title="GRU 门控循环单元"></a>GRU 门控循环单元</h1><p><em>RNN无法处理较长数据，所有信息都在隐藏状态中，时间较长时累计状态过多，之前的信息不好做抽取。</em></p><p><strong>GRU思想：不是每个观察值都同等重要</strong></p><p><strong>通过门控单元，选择重要的内容 忘记不重要的内容</strong></p><h2 id="1-门控隐状态"><a href="#1-门控隐状态" class="headerlink" title="1.门控隐状态"></a>1.门控隐状态</h2><p>门控循环单元与普通的循环神经网络之间的关键区别在于： 前者支持隐状态的门控。</p><p>门控循环单元模型有专门的机制来确定应该何时更新隐状态， 以及应该何时重置隐状态。 </p><p><strong>隐状态三种情况：</strong></p><ol><li>如果第一个词元非常重要， 模型将学会在第一次观测之后不更新隐状态。 </li><li>同样，模型也可以学会跳过不相关的临时观测。</li><li>最后，模型还将学会在需要的时候重置隐状态。</li></ol><h3 id="1-1重置门和更新门"><a href="#1-1重置门和更新门" class="headerlink" title="1.1重置门和更新门"></a>1.1重置门和更新门</h3><p>我们把更新门和重置门设计成(0,1)区间中的向量，进行凸组合</p><ul><li><strong>更新门</strong> 能关注的机制 控制“可能还想记住”的过去状态的数量</li><li><strong>重置门（遗忘门）</strong> 能遗忘的机制 控制新状态中有多少个是旧状态的副本</li></ul><p>下图描述门控循环单元中的重置门和更新门的输入， 输入是由当前时间步的输入和前一时间步的隐状态给出。 两个门的输出是由使用sigmoid激活函数的两个全连接层给出。</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230321171826823.png" alt="" style="zoom: 80%;" /></p><p>对于时间步$t$，假设输入是一个小批量$X_t \in \mathbb {R} ^{n*d}$ (样本个数$n$，输入个数$d$)，</p><p>上一步时间步的隐状态是 $H_{t-1}\in\mathbb{R}^{n*h}$ （隐藏单元个数$h$）。</p><p>重置门 $R_t\in\mathbb{R}^{n*h}$</p><p>更新门  $Z_t\in\mathbb{R}^{n*h}$ </p><p>计算如下所示：</p><script type="math/tex; mode=display">R_t=\alpha(X_tW_{xr}+H_{t-1}W_{hr}+b_r) \tag{1.1.1} \\ Z_t=\alpha(X_tW_{xz}+H_{t-1}W_{hz}+b_z)</script><p>$W_{xr},W_{xz} \in \mathbb{R}^{d*h}$ </p><p>$W_{hr},W_{hz} \in \mathbb{R}^{h*h}$是权重参数</p><p>$b_r，b_z \in \mathbb{R}^{1*h}$是偏置参数</p><p><strong>在求和过程中会触发广播机制。</strong>同时使用sigmoid函数将输入值转换到区间$(0,1)$</p><h3 id="1-2候选隐状态"><a href="#1-2候选隐状态" class="headerlink" title="1.2候选隐状态"></a>1.2候选隐状态</h3><p>我们将重置门$R_t$与RNN中的常规隐状态更新机制集成，得到在时间步$t$的候选隐状态$\tilde{H}_t \in \mathbb {R}^{n*h}$。</p><script type="math/tex; mode=display">\tilde{H}_t = tanh(X_tW_{xh}+(R_t \odot H_{t-1})W_{hh}+b_h) \tag{1.2.1}</script><p>$W_{xh}\in\mathbb{R}^{d*h}$ </p><p>$W_{hh} \in \mathbb{R}^{h*h}$ 是权重参数</p><p>$b_h \in \mathbb {R}^{1*h}$是偏置项</p><p>符号 $\odot$ 是Hadamard积（按照元素乘积）运算符</p><p>在这里，我们使用tanh非线性激活函数来确保候选隐状态中的值保持在区间$(-1，1)$中。</p><p>与RNN的常规隐状态相比，$(1.2.1)$中的$R_t$和$H_{t-1}$的元素相乘可以减少以往状态的影响。</p><p><strong>每当重置门$R_t$中的项接近1时，我们恢复一个例如RNN的常规隐状态的普通循环神经网络。</strong></p><p><strong>对于重置门$R_t$中所有接近0的项，候选隐状态是以$X_t$作为输入的多层感知机的结果。</strong></p><p>因此，任何预先存在的隐状态都会被重置为默认值。</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230322104641189.png" alt="" style="zoom:67%;" /></p><p>上图说明了应用重置门之后的计算流程。</p><h3 id="1-3隐状态"><a href="#1-3隐状态" class="headerlink" title="1.3隐状态"></a>1.3隐状态</h3><p>上述的计算结果只是候选隐状态，我们仍然需要结合更新门$Z_t$的效果。 </p><p><strong>这一步确定新的隐状态$H_t \in \mathbb{R}^{n*h}$在多大程度上来自旧的状态$H_{t-1}$和新的候选状态$\tilde{H}_t$。</strong></p><p><strong>更新门$Z_t$仅需要在$H_{t-1}$和$H_{t}$之间进行按元素的凸组合就可以实现这个目标。</strong> </p><p>这就得出了门控循环单元的最终更新公式：</p><script type="math/tex; mode=display">H_t = Z_t \odot H_{t-1}+(1-Z_t) \odot \tilde{H}_t \tag{1.3.1}</script><p><strong>每当更新门$Z_t$接近1时，模型就倾向只保留旧状态。</strong> </p><p><strong>此时，来自$X_t$的信息基本上被忽略，从而有效地跳过了依赖链条中的时间步$t$。</strong></p><p><strong>相反，当$Z_t$接近0时， 新的隐状态$H_t$就会接近候选隐状态$\tilde{H}_t$。</strong></p><p><strong>这些设计可以帮助我们处理循环神经网络中的梯度消失问题，并更好地捕获时间步距离很长的序列的依赖关系。</strong> </p><p>例如，如果整个子序列的所有时间步的更新门都接近于1，则无论序列的长度如何，在序列起始时间步的旧隐状态都将很容易保留并传递到序列结束。</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230322110327072.png" alt="" style="zoom:80%;" /></p><p>上图说明了更新门起作用后的计算流。</p><h2 id="2-特征"><a href="#2-特征" class="headerlink" title="2.特征"></a>2.特征</h2><p>GRU有以下俩个显著特征：</p><ul><li><strong>重置门有助于捕获序列中的短期依赖关系</strong></li><li><strong>更新门有助于捕获序列中的长期依赖关系</strong></li></ul><h2 id="3-参考网站"><a href="#3-参考网站" class="headerlink" title="3.参考网站"></a>3.参考网站</h2><p><a href="https://www.bilibili.com/video/BV1mf4y157N2/?spm_id_from=333.999.0.0&amp;vd_source=5cf963abd0f635e31aa9385d489cf581">https://www.bilibili.com/video/BV1mf4y157N2/?spm_id_from=333.999.0.0&amp;vd_source=5cf963abd0f635e31aa9385d489cf581</a></p><p><a href="https://zh-v2.d2l.ai/chapter_recurrent-modern/gru.html#id4">https://zh-v2.d2l.ai/chapter_recurrent-modern/gru.html#id4</a></p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GRU </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LSTM</title>
      <link href="/2023/03/23/LSTM/"/>
      <url>/2023/03/23/LSTM/</url>
      
        <content type="html"><![CDATA[<h1 id="LSTM-长短期记忆网络"><a href="#LSTM-长短期记忆网络" class="headerlink" title="LSTM 长短期记忆网络"></a>LSTM 长短期记忆网络</h1><p><strong>长期以来，隐变量模型存在着长期信息保存和短期输入缺失的问题。</strong> </p><p>解决这一问题的最早方法之一是长短期存储器（long short-term memory，LSTM）。</p><h2 id="1-实现效果"><a href="#1-实现效果" class="headerlink" title="1. 实现效果"></a>1. 实现效果</h2><ul><li><p>忘掉过去状态，尽量去看现在的输入数据</p></li><li><p>不看现在的输入数据，尽量去看前一个的状态</p></li></ul><h2 id="2-模型组成"><a href="#2-模型组成" class="headerlink" title="2. 模型组成"></a>2. 模型组成</h2><h3 id="2-1门控记忆单元"><a href="#2-1门控记忆单元" class="headerlink" title="2.1门控记忆单元"></a>2.1门控记忆单元</h3><p>可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。</p><p>长短期记忆网络引入了<strong>记忆元</strong>，或简称为单元（cell）。有些文献认为记忆元是隐状态的一种特殊类型，它们与隐状态具有相同的形状，其<strong>设计目的是用于记录附加的信息</strong>。</p><p>为了控制记忆元，我们需要许多门。<strong>其中一个门用来从单元中输出条目，我们将其称为输出门（output gate）。另外一个门用来决定何时将数据读入单元，我们将其称为输入门（input gate）。</strong></p><p>我们还需要一种机制来<strong>重置单元的内容，由遗忘门（forget gate）来管理</strong>， 这种设计的动机与门控循环单元相同，能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。</p><ul><li><p>遗忘门：将值朝0减少</p></li><li><p>输入门：决定不是忽略掉输入数据</p></li><li><p>输出门：决定是不是使用隐状态</p></li></ul><h3 id="2-2输入门、忘记门和输出门"><a href="#2-2输入门、忘记门和输出门" class="headerlink" title="2.2输入门、忘记门和输出门"></a>2.2输入门、忘记门和输出门</h3><p>就如在门控循环单元中一样， 当前时间步的输入和前一个时间步的隐状态作为数据送入长短期记忆网络的门中， 如图所示。它们由三个具有sigmoid激活函数的全连接层处理，以计算输入门、遗忘门和输出门的值。因此，这三个门的值都在(0,1)的范围内。</p><p><img src="http://yanhaoli-images.oss-cn-beijing.aliyuncs.com/img/image-20230322113226798.png" alt="" style="zoom:80%;" /></p><p><strong>长短期记忆网络的数学表达。</strong></p><p>假设有$ℎ$个隐藏单元，批量大小为$n$，输入数为$d$。 </p><p>输入为$X_t \in \mathbb {R}^{n*d}$</p><p>前一时间步的隐状态为$H_{t-1} \in \mathbb {R}^{n*h}$。 </p><p>相应地，时间步$t$的门被定义如下：</p><p>输入门是$I_t \in \mathbb {R}^{n*h}$ </p><p>遗忘门是$F_t \in \mathbb {R}^{n*h}$</p><p> 输出门是$O_t \in \mathbb {R}^{n*h}$。</p><p>它们的计算方法如下：</p><script type="math/tex; mode=display">I_t=\alpha(X_tW_{xi}+H_{t-1}W_{hi}+b_i)\\F_t=\alpha(X_tW_{xf}+H_{t-1}W_{hf}+b_f)\\O_t=\alpha(X_tW_{xo}+H_{t-1}W_{ho}+b_o)\\ \tag{2.2.1}</script>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> LSTM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/03/23/hello-world/"/>
      <url>/2023/03/23/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
